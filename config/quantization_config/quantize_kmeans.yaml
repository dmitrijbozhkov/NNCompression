is_quantize: true
quantization_type: batched_kmeans
quantize_levels: [2, 4, 8, 16, 32, 64, 128, 256]
